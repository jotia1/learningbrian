{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for batching\n",
    "Now the basic structure of the spiking neural networks has been made it is time to tidy the code and prepare it for batch runs on the Goliath cluster. The next cell will form a support file for reading and graphing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # must be done on cluster as there is no display\n",
    "from brian2 import *\n",
    "import struct\n",
    "import os\n",
    "\n",
    "V3 = \"aedat3\"\n",
    "V2 = \"aedat\"  # current 32bit file format\n",
    "V1 = \"dat\"  # old format\n",
    "\n",
    "EVT_DVS = 0  # DVS event type\n",
    "EVT_APS = 1  # APS event\n",
    "\n",
    "RESX = 128\n",
    "RESY = 128\n",
    "RES = RESX * RESY\n",
    "COLOURS = ['r', 'g', 'b', 'm', 'c', 'm', 'y', 'k']\n",
    "\n",
    "##      Some helpful functions\n",
    "flatIndex = lambda x, y : y*RESX + x\n",
    "squareIndex = lambda i : (i % 128, int(i / 128))  # TODO there is probably some math todo for DAVIS \n",
    "\n",
    "\n",
    "\n",
    "def loadaerdat(datafile='/tmp/aerout.dat', length=0, version=V2, debug=1, camera='DVS128'):\n",
    "    \"\"\"    \n",
    "    load AER data file and parse these properties of AE events:\n",
    "    - timestamps (in us), \n",
    "    - x,y-position [0..127]\n",
    "    - polarity (0/1)\n",
    "\n",
    "    @param datafile - path to the file to read\n",
    "    @param length - how many bytes(B) should be read; default 0=whole file\n",
    "    @param version - which file format version is used: \"aedat\" = v2, \"dat\" = v1 (old)\n",
    "    @param debug - 0 = silent, 1 (default) = print summary, >=2 = print all debug\n",
    "    @param camera='DVS128' or 'DAVIS240'\n",
    "    @return (ts, xpos, ypos, pol) 4-tuple of lists containing data of all events;\n",
    "    \"\"\"\n",
    "    # constants\n",
    "    aeLen = 8  # 1 AE event takes 8 bytes\n",
    "    readMode = '>II'  # struct.unpack(), 2x ulong, 4B+4B\n",
    "    td = 0.000001  # timestep is 1us   \n",
    "    if(camera == 'DVS128'):\n",
    "        xmask = 0x00fe\n",
    "        xshift = 1\n",
    "        ymask = 0x7f00\n",
    "        yshift = 8\n",
    "        pmask = 0x1\n",
    "        pshift = 0\n",
    "    elif(camera == 'DAVIS240'):  # values take from scripts/matlab/getDVS*.m\n",
    "        xmask = 0x003ff000\n",
    "        xshift = 12\n",
    "        ymask = 0x7fc00000\n",
    "        yshift = 22\n",
    "        pmask = 0x800\n",
    "        pshift = 11\n",
    "        eventtypeshift = 31\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported camera: %s\" % (camera))\n",
    "\n",
    "    if (version == V1):\n",
    "        print (\"using the old .dat format\")\n",
    "        aeLen = 6\n",
    "        readMode = '>HI'  # ushot, ulong = 2B+4B\n",
    "\n",
    "    aerdatafh = open(datafile, 'rb')\n",
    "    k = 0  # line number\n",
    "    p = 0  # pointer, position on bytes\n",
    "    statinfo = os.stat(datafile)\n",
    "    if length == 0:\n",
    "        length = statinfo.st_size    \n",
    "    print (\"file size\", length)\n",
    "    \n",
    "    # header\n",
    "    lt = aerdatafh.readline().decode('utf-8')\n",
    "    while lt and lt[0] == \"#\":\n",
    "        p += len(lt)\n",
    "        k += 1\n",
    "        lt = aerdatafh.readline().decode('utf-8') \n",
    "        if lt.startswith('#End of Preferences'):\n",
    "            p += len(lt)   # TODO this is a bit lazy, rearrange logic\n",
    "            k += 1\n",
    "            break\n",
    "        if debug >= 2:\n",
    "            #print (str(lt))\n",
    "            pass\n",
    "        continue\n",
    "    \n",
    "    # variables to parse\n",
    "    timestamps = []\n",
    "    xaddr = []\n",
    "    yaddr = []\n",
    "    pol = []\n",
    "    \n",
    "    # read data-part of file\n",
    "    aerdatafh.seek(p)\n",
    "    s = aerdatafh.read(aeLen)\n",
    "    p += aeLen\n",
    "    length += p\n",
    "    \n",
    "    #print (xmask, xshift, ymask, yshift, pmask, pshift, aeLen,  p, length)    \n",
    "    while p < length:\n",
    "        #print (xmask, xshift, ymask, yshift, pmask, pshift, aeLen,  p, length)\n",
    "        #ii = int.from_bytes(s, byteorder='big')\n",
    "        #print(str(bin(ii)), len(str(bin(ii))))\n",
    "        #print(type(s))\n",
    "        addr, ts = struct.unpack(readMode, s)\n",
    "        \n",
    "        # parse event type\n",
    "        if(camera == 'DAVIS240'):\n",
    "            eventtype = (addr >> eventtypeshift)\n",
    "        else:  # DVS128\n",
    "            eventtype = EVT_DVS\n",
    "        \n",
    "        # parse event's data\n",
    "        if(eventtype == EVT_DVS):  # this is a DVS event\n",
    "            #print(str(bin(addr)), len(str(bin(addr))))\n",
    "            x_addr = (addr & xmask) >> xshift\n",
    "            y_addr = (addr & ymask) >> yshift\n",
    "            a_pol = (addr & pmask) >> pshift\n",
    "\n",
    "\n",
    "            if debug >= 3: \n",
    "                print(\"ts->\", ts)  # ok\n",
    "                print(\"x-> \", x_addr)\n",
    "                print(\"y-> \", y_addr)\n",
    "                print(\"pol->\", a_pol)\n",
    "\n",
    "            timestamps.append(ts)\n",
    "            xaddr.append(x_addr)\n",
    "            yaddr.append(y_addr)\n",
    "            pol.append(a_pol)\n",
    "            #poldf\n",
    "        \n",
    "        aerdatafh.seek(p)\n",
    "        s = aerdatafh.read(aeLen)\n",
    "        p += aeLen        \n",
    "\n",
    "    if debug > 0:\n",
    "        print(len(timestamps))\n",
    "        try:\n",
    "            print (\"read %i (~ %.2fM) AE events, duration= %.2fs\" % (len(timestamps), len(timestamps) / float(10 ** 6), (timestamps[-1] - timestamps[0]) * td))\n",
    "            n = 5\n",
    "            print (\"showing first %i:\" % (n))\n",
    "            print (\"timestamps: %s \\nX-addr: %s\\nY-addr: %s\\npolarity: %s\" % (timestamps[0:n], xaddr[0:n], yaddr[0:n], pol[0:n]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print (\"failed to print statistics\")\n",
    "\n",
    "    return timestamps, xaddr, yaddr, pol\n",
    "\n",
    "\n",
    "def rec_field(ofx, ofy, sizex, sizey, stim_res_x=RESX, stim_res_y=RESY):\n",
    "    \"\"\" Given the offset in (x,y) and a size in x and y return a receptive field\n",
    "        as a list of indices assuming camera stimulus if not specified for stim_res_*\n",
    "        The offset plus corresponding size will not excede the retina\n",
    "    \"\"\"\n",
    "    if ofx + sizex >= stim_res_x:\n",
    "        sizex = stim_res_x - ofx\n",
    "    if ofy + sizey >= stim_res_y:\n",
    "        sizey = stim_res_y - ofy\n",
    "    return [flatIndex(x, y) for x in range(ofx, sizex+ofx) for y in range(ofy, sizey+ofy)]\n",
    "\n",
    "def dvs2group(xs, ys, ts):\n",
    "    \"\"\" Given DVS data convert it to indices and timestamps that can be used by a Brian2 Spiking\n",
    "        Neuron group. \n",
    "    \"\"\"\n",
    "    # TODO This means no 2 distinct neurons can fire at the same us.... Needs a fix\n",
    "    real_indices = [flatIndex(*xy) for xy in zip(xs, ys)]\n",
    "    real_times, uniq_idxs = np.unique(ts, return_index=True)\n",
    "    real_indices = np.asarray(real_indices)[uniq_idxs]\n",
    "    real_times = (real_times - real_times[0])*us\n",
    "    return (real_indices, real_times)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##   SOMEWHAT CONSTANTS\n",
    "defaultclock.dt = 1*us\n",
    "tau = 10*ms\n",
    "eqs = '''\n",
    "dv/dt = (I - v) / tau : 1 (unless refractory)  # Pick any model\n",
    "I = 0: 1\n",
    "'''\n",
    "## LOAD REAL DATA\n",
    "file = 'M1a_expand.aedat'\n",
    "bytes2read = 30000\n",
    "# Finally load and process the data once\n",
    "ts, xs, ys, ps = loadaerdat(datafile=file, length=bytes2read, version='aedat', debug=0, camera='DVS128')\n",
    "real_indices, real_times = dvs2group(xs, ys, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now defining the actual network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    field_size=32\n",
    "    stride=16\n",
    "    dist = lambda p1, p2: np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "    for field_size in [32, 16]:\n",
    "\n",
    "        field_sqrd = field_size * field_size\n",
    "        surfs = []\n",
    "        surf_names = 'CE'#'CELRDU'\n",
    "        ##                              Add expansions\n",
    "        mid = (field_size - 1) / 2 \n",
    "        max_dist = dist((0,0), (mid, mid))\n",
    "        surfs.append(np.array([ dist((i%field_size, i // field_size), (mid, mid)) for i in range(field_sqrd)])/max_dist) # Contraction\n",
    "        surfs.append(1 - surfs[-1])                                                                   # Expansion\n",
    "        ##                              Add horizontal and vertical\n",
    "        #surfs.append(np.array([(i%field_size)/field_size for i in range(field_sqrd)]))                #left active\n",
    "        #surfs.append(np.array([(field_size - (i%field_size))/field_size for i in range(field_sqrd)])) #right active\n",
    "        #surfs.append(1 - surfs[-1])\n",
    "        #surfs.append(np.array([(i//field_size)/field_size for i in range(field_sqrd)]))         #down active\n",
    "        #surfs.append(np.array([1 - (i//field_size)/field_size for i in range(field_sqrd)]))       #up active\n",
    "        #surfs.append(1 - surfs[-1])\n",
    "\n",
    "        for stride in [16, 8]:\n",
    "            for s_num in range(len(surfs)):\n",
    "                surface = surfs[s_num]\n",
    "                #print(surf.shape)\n",
    "                name = '{}_{}field_{}stride.png'.format(surf_names[s_num], field_size, stride)\n",
    "                voltMon, spikeMon_opt, locs, rcsizes = make_network(surface, field_size, stride)           # Make network\n",
    "                graph_network(voltMon, spikeMon_opt, locs, rcsizes, surface, save=name)                    # Graph network\n",
    "\n",
    "\n",
    "\n",
    "def make_network(surface, field_size=32, stride=8):\n",
    "    start_scope()\n",
    "\n",
    "    # build receptive fields\n",
    "    field_sqrd = field_size * field_size\n",
    "    inp = SpikeGeneratorGroup(RES, real_indices, real_times)\n",
    "\n",
    "    G, S, locs = conv_layer(inp, (RESY, RESY), surface, (field_size, field_size), stride)\n",
    "    rcsizes = [(field_size, field_size) for i in range(len(locs))]\n",
    "    G.v = 0.1\n",
    "\n",
    "    voltMon = StateMonitor(G, 'v', record=True)\n",
    "    spikeMon_opt = SpikeMonitor(G)\n",
    "    \n",
    "    run(60*ms)\n",
    "\n",
    "    return (voltMon, spikeMon_opt, locs, rcsizes)\n",
    "\n",
    "\n",
    "def graph_network(voltMon, spikeMon_opt, locs, rcsizes, surface, save=False):\n",
    "    figure(figsize=(14, 12))\n",
    "    suptitle('{} #neurons: '.format(save) + str(len(locs)))\n",
    "    subplot(221)\n",
    "    for n in range(len(locs)):\n",
    "        plot(voltMon.t/ms, voltMon.v[n], '-'+COLOURS[n%len(COLOURS)], lw=1, label='N'+str(n))\n",
    "\n",
    "    axhline(0.7, ls=':', c='g', lw=3)  # Threshold line\n",
    "    xlabel('Time (ms)')\n",
    "    ylabel('v')\n",
    "    title('Membrane potentials')\n",
    "\n",
    "    #legend(loc='best')\n",
    "\n",
    "    # Plot image and RC locations\n",
    "    ax = subplot(222)\n",
    "    plot(xs, ys, '.k')\n",
    "    for n in range(len(locs)):\n",
    "        ax.add_patch(Rectangle(locs[n], *(rcsizes[n]), lw=3, color=COLOURS[n%len(COLOURS)], fill=False))\n",
    "    title('Receptive fields of each kernel')\n",
    "\n",
    "    subplot(223)\n",
    "    vis_surface(surface, field_size, field_size)\n",
    "    title('Convolution kernel')\n",
    "\n",
    "    subplot(224)\n",
    "    title('Number of output spikes from each neuron in second layer')\n",
    "    vis_output(spikeMon_opt, np.sqrt(len(locs)), np.sqrt(len(locs)))\n",
    "    \n",
    "    if save:\n",
    "        savefig(save, bbox_inches='tight')\n",
    "\n",
    "def vis_output(spikeMon, resx, resy):\n",
    "    \"\"\" Given a spikeMonitor with variables t and i identifying neurons convert\n",
    "        back to 2D coordinates and plot the response\n",
    "    \"\"\"\n",
    "    times = spikeMon.t\n",
    "    indexs_2dx = [i % resx for i in spikeMon.i]\n",
    "    indexs_2dy = [int(i / resy) for i in spikeMon.i]\n",
    "    \n",
    "    heatmap, xedges, yedges = np.histogram2d(indexs_2dx, indexs_2dy, bins=resx)\n",
    "    extent = [0,resx, 0,resy]#[xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    imshow(heatmap.T, extent=extent, origin='lower', interpolation='None')\n",
    "    colorbar()\n",
    "\n",
    "def vis_surface(surface, sizex=None, sizey=None):\n",
    "    \"\"\" Given a surface draw it as a heatmap. If size not supplied, render in current\n",
    "        shape, otherwise reshape to sizes given. Both arguements required or\n",
    "        no reshaping will happen.\n",
    "    \"\"\"\n",
    "    res = surface\n",
    "    if sizex != None and sizey != None:\n",
    "        res = np.zeros(shape=(sizey, sizex))\n",
    "        for i in range(sizey):\n",
    "            res[i, :] = surface[i*sizex : (i+1)*sizex]\n",
    "            \n",
    "    imshow(res, interpolation='None')\n",
    "    colorbar()\n",
    "    \n",
    "def conv_layer(layer, layer_rc, kernel, kernel_rc, stride):\n",
    "    \"\"\" Given a neuron layer and a surface (kernel of weights), create a set of synapses\n",
    "        and a new layer that convolves that surface with the neuron layer with stride stride. \n",
    "        Returns tuple of (new_layer, new_synapses, locations)\n",
    "\n",
    "        layer - a (NeuronGroup) group of neurons being input to new layer\n",
    "        layer_rc - number of rows and colums of layer as tuple (row, col)\n",
    "        kernel - 1D array of weights to be used as convolution kernel\n",
    "        kernel_rc - rows and cols of kernel\n",
    "        stride - stride between kernel convolutions\n",
    "        locations - location of each receptive field\n",
    "    \"\"\"\n",
    "    kr, kc = kernel_rc\n",
    "    lr, lc = layer_rc\n",
    "    \n",
    "    r, c = (0, 0)\n",
    "    locs = []  # Compute bottom left corner of each position for kernel\n",
    "    while c + kc <= lc:    # TODO this can be faster if done analytically... \n",
    "        r = 0\n",
    "        while r + kr <= lr:\n",
    "            locs.append((r,c))\n",
    "            r += stride\n",
    "        c += stride\n",
    "            \n",
    "    print(\"Loc Num: \", len(locs))        \n",
    "    ng = NeuronGroup(len(locs), eqs, threshold='v>0.7', reset='v=0.1', method='linear', refractory=5*ms)\n",
    "    syns = Synapses(layer, ng, 'w : 1', on_pre='v_post += w')\n",
    "    \n",
    "    for n in range(len(locs)):\n",
    "        arr = np.array(rec_field(*(locs[n]), kr, kc))\n",
    "        syns.connect(i=arr, j=n)\n",
    "        syns.w[:, n] = surface*0.05\n",
    "    \n",
    "    return (ng, syns, locs)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
